"""add full_name to users

Revision ID: 9da49df11bd2
Revises: 77e193bdc0ff
Create Date: 2026-01-05 21:54:41.432742

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision = '9da49df11bd2'
down_revision = '77e193bdc0ff'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_table('record')
    with op.batch_alter_table('record_history', schema=None) as batch_op:
        batch_op.alter_column('timestamp',
               existing_type=postgresql.TIMESTAMP(),
               nullable=True)
        batch_op.drop_constraint(batch_op.f('record_history_record_id_fkey'), type_='foreignkey')
        batch_op.create_foreign_key(None, 'records', ['record_id'], ['id'])

    with op.batch_alter_table('records', schema=None) as batch_op:
        batch_op.alter_column('document_id',
               existing_type=sa.VARCHAR(length=32),
               type_=sa.String(length=50),
               existing_nullable=False)
        batch_op.alter_column('title',
               existing_type=sa.VARCHAR(length=200),
               type_=sa.String(length=255),
               existing_nullable=False)
        batch_op.alter_column('doc_type',
               existing_type=sa.VARCHAR(length=100),
               type_=sa.String(length=50),
               existing_nullable=False)
        batch_op.alter_column('released_by',
               existing_type=sa.VARCHAR(length=100),
               nullable=True)
        batch_op.alter_column('received_by',
               existing_type=sa.VARCHAR(length=100),
               nullable=True)
        batch_op.drop_column('remarks')
        batch_op.drop_column('updated_at')

    with op.batch_alter_table('users', schema=None) as batch_op:
        batch_op.add_column(sa.Column('full_name', sa.String(length=150), nullable=False))
        batch_op.alter_column('department',
               existing_type=sa.VARCHAR(length=255),
               type_=sa.String(length=100),
               existing_nullable=True)

    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table('users', schema=None) as batch_op:
        batch_op.alter_column('department',
               existing_type=sa.String(length=100),
               type_=sa.VARCHAR(length=255),
               existing_nullable=True)
        batch_op.drop_column('full_name')

    with op.batch_alter_table('records', schema=None) as batch_op:
        batch_op.add_column(sa.Column('updated_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=True))
        batch_op.add_column(sa.Column('remarks', sa.TEXT(), autoincrement=False, nullable=True))
        batch_op.alter_column('received_by',
               existing_type=sa.VARCHAR(length=100),
               nullable=False)
        batch_op.alter_column('released_by',
               existing_type=sa.VARCHAR(length=100),
               nullable=False)
        batch_op.alter_column('doc_type',
               existing_type=sa.String(length=50),
               type_=sa.VARCHAR(length=100),
               existing_nullable=False)
        batch_op.alter_column('title',
               existing_type=sa.String(length=255),
               type_=sa.VARCHAR(length=200),
               existing_nullable=False)
        batch_op.alter_column('document_id',
               existing_type=sa.String(length=50),
               type_=sa.VARCHAR(length=32),
               existing_nullable=False)

    with op.batch_alter_table('record_history', schema=None) as batch_op:
        batch_op.drop_constraint(None, type_='foreignkey')
        batch_op.create_foreign_key(batch_op.f('record_history_record_id_fkey'), 'records', ['record_id'], ['id'], ondelete='CASCADE')
        batch_op.alter_column('timestamp',
               existing_type=postgresql.TIMESTAMP(),
               nullable=False)

    op.create_table('record',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('document_id', sa.VARCHAR(length=50), autoincrement=False, nullable=False),
    sa.Column('title', sa.VARCHAR(length=255), autoincrement=False, nullable=False),
    sa.Column('doc_type', sa.VARCHAR(length=50), autoincrement=False, nullable=False),
    sa.Column('department', sa.VARCHAR(length=100), autoincrement=False, nullable=False),
    sa.Column('date_in', sa.DATE(), autoincrement=False, nullable=False),
    sa.Column('amount', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('released_by', sa.VARCHAR(length=100), autoincrement=False, nullable=True),
    sa.Column('received_by', sa.VARCHAR(length=100), autoincrement=False, nullable=True),
    sa.Column('status', sa.VARCHAR(length=50), autoincrement=False, nullable=False),
    sa.Column('created_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
    sa.PrimaryKeyConstraint('id', name=op.f('record_pkey')),
    sa.UniqueConstraint('document_id', name=op.f('record_document_id_key'), postgresql_include=[], postgresql_nulls_not_distinct=False)
    )
    # ### end Alembic commands ###
